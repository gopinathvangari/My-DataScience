{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "metadata": {
        "id": "iD5Bj3mf9WxO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "f46a4e24-a50c-41e8-9c6a-3e610650755d"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "400a3cd5-1851-4274-d655-fd76242f7d32"
      },
      "cell_type": "code",
      "source": [
        "# Number of samples in the train data\n",
        "x_train.shape[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "zewyDcBlJjv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a30132c-8e05-4362-a158-e4ccb42cf969"
      },
      "cell_type": "code",
      "source": [
        "# Number of samples in the test data\n",
        "x_test.shape[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81586962-7441-4e3c-feb6-064243610460"
      },
      "cell_type": "code",
      "source": [
        "# Dimensions of the image in the dataset\n",
        "x_train.shape[1:3]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73834802-a3e8-4f2f-b5a9-2d6bd5523655"
      },
      "cell_type": "code",
      "source": [
        "np.unique(y_train)\n",
        "np.unique(y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Pwc163OR841C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# There are 10 unique values in the label data. Hence converting the labels to one hot vectors with 10 variables\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Min-Max normalization\n",
        "# Dividing all the values by 255 as min.value = 0 & max.value = 255\n",
        "\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.reshape(x_train,(60000,28,28,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zk6wkFINGS6H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = np.reshape(x_test,(10000,28,28,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAtpPiIlGYuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "add707d7-e025-414f-ab6f-3adcc92ed2f1"
      },
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "mwaa3TbfGbmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c098f59a-1141-455c-9276-5a047a62b56a"
      },
      "cell_type": "code",
      "source": [
        "x_test[0].shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3*3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "#Initialize model\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E1swotPaHcQx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add first convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(32, #Number of filters \n",
        "                                 kernel_size=(3,3), #Size of the filter\n",
        "                                 activation='relu'))\n",
        "\n",
        "#Add second convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6-UzD3CyHuUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQgiZC12IjtP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "72ccfec8-b175-4d95-9a2e-0e7e0f02185a"
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5jzrRKfQLK18",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(patience=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmYFX-RLIrpy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "ba065469-3fd6-4108-8e0d-fc256196b4d0"
      },
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "model.fit(x_train,y_train,          \n",
        "          validation_data=(x_test,y_test),\n",
        "          epochs=10,\n",
        "          batch_size=32,callbacks =[callback])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 14s 233us/sample - loss: 0.3868 - acc: 0.8625 - val_loss: 0.3181 - val_acc: 0.8889\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 10s 175us/sample - loss: 0.2428 - acc: 0.9106 - val_loss: 0.2592 - val_acc: 0.9061\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 184us/sample - loss: 0.1793 - acc: 0.9327 - val_loss: 0.2521 - val_acc: 0.9131\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 11s 177us/sample - loss: 0.1261 - acc: 0.9539 - val_loss: 0.2603 - val_acc: 0.9160\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 174us/sample - loss: 0.0844 - acc: 0.9692 - val_loss: 0.3094 - val_acc: 0.9092\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 11s 175us/sample - loss: 0.0553 - acc: 0.9797 - val_loss: 0.3757 - val_acc: 0.9113\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 10s 175us/sample - loss: 0.0398 - acc: 0.9855 - val_loss: 0.3994 - val_acc: 0.9119\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 10s 174us/sample - loss: 0.0268 - acc: 0.9905 - val_loss: 0.4169 - val_acc: 0.9148\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e96777160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "#Initialize model\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zQu6wu6M8Yf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add first convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(32, #Number of filters \n",
        "                                 kernel_size=(3,3), #Size of the filter\n",
        "                                 activation='relu'))\n",
        "\n",
        "#Add second convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f020kI7yNFMv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add MaxPooling layer\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8gIj47QKNdp1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add dropout layer\n",
        "model.add(tf.keras.layers.Dropout(0.25))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_U80E9zpNG3b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RZQYJ3G_NLak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZDebAsY6NOvD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(patience=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCIe9r5RNRcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "f3849c31-b4bb-4439-c7a3-4e6442a3d63f"
      },
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "model.fit(x_train,y_train,          \n",
        "          validation_data=(x_test,y_test),\n",
        "          epochs=10,\n",
        "          batch_size=32,callbacks =[callback])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 173us/sample - loss: 0.3955 - acc: 0.8575 - val_loss: 0.2923 - val_acc: 0.8942\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.2573 - acc: 0.9048 - val_loss: 0.2708 - val_acc: 0.8984\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.2108 - acc: 0.9208 - val_loss: 0.2426 - val_acc: 0.9091\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 0.1768 - acc: 0.9340 - val_loss: 0.2329 - val_acc: 0.9146\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 156us/sample - loss: 0.1511 - acc: 0.9429 - val_loss: 0.2234 - val_acc: 0.9230\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 10s 163us/sample - loss: 0.1284 - acc: 0.9513 - val_loss: 0.2290 - val_acc: 0.9264\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 150us/sample - loss: 0.1085 - acc: 0.9592 - val_loss: 0.2345 - val_acc: 0.9255\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0949 - acc: 0.9642 - val_loss: 0.2475 - val_acc: 0.9261\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.0835 - acc: 0.9689 - val_loss: 0.2554 - val_acc: 0.9270\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 148us/sample - loss: 0.0701 - acc: 0.9743 - val_loss: 0.2854 - val_acc: 0.9258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e807edd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "Rz4p2TC8M1Rx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "metadata": {
        "id": "kL1iwmx4M7BP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "955722f5-26f4-4448-d4c4-d80c03d98f7f"
      },
      "cell_type": "code",
      "source": [
        "# Final Train Loss & Accuracy\n",
        "model.evaluate(x_train,y_train)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0427 - acc: 0.9851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04274336954456133, 0.98515]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a9b3a2c9-415c-43bf-b31f-32fee2feb87e"
      },
      "cell_type": "code",
      "source": [
        "# Final Validation Loss & Accuracy\n",
        "model.evaluate(x_test,y_test)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 57us/sample - loss: 0.2854 - acc: 0.9258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.28536631895303727, 0.9258]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}