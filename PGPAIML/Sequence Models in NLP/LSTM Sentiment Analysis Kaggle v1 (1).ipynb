{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"LSTM Sentiment Analysis Kaggle v1 (1).ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"oK3vS0TNN4XD","colab_type":"code","colab":{},"outputId":"decfea97-6b8e-4efb-bfbc-d61d2e4e5286"},"source":["#Import libraries\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n","from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical\n","import re"],"execution_count":0,"outputs":[{"output_type":"stream","text":["C:\\Users\\Amit\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oSdOMM5lN4XH","colab_type":"code","colab":{}},"source":["data = pd.read_csv('./data/Sentiment.csv')\n","# Keeping only the neccessary columns\n","data = data[['text','sentiment']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0xcEHlaN4Xs","colab_type":"code","colab":{},"outputId":"cf1a0511-f306-44f2-8584-ed543a2ddfab"},"source":["data = data[data.sentiment != \"Neutral\"]\n","data['text'] = data['text'].apply(lambda x: x.lower())\n","data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n","\n","print(data[ data['sentiment'] == 'Positive'].size)\n","print(data[ data['sentiment'] == 'Negative'].size)\n","\n","for idx,row in data.iterrows():\n","    row[0] = row[0].replace('rt',' ')\n","    \n","vocabSize = 2000\n","tokenizer = Tokenizer(num_words=vocabSize, split=' ')\n","tokenizer.fit_on_texts(data['text'].values)\n","X = tokenizer.texts_to_sequences(data['text'].values)\n","X = pad_sequences(X)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["4472\n","16986\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"93z-l-owN4Xu","colab_type":"code","colab":{},"outputId":"f92d8f0f-f69c-467a-c357-2f13a6354998"},"source":["embed_dim = 128\n","lstm_out = 196\n","\n","model = Sequential()\n","model.add(Embedding(vocabSize, embed_dim,input_length = X.shape[1]))\n","model.add(SpatialDropout1D(0.4))\n","model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(2,activation='softmax'))\n","model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n","print(model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 28, 128)           256000    \n","_________________________________________________________________\n","spatial_dropout1d_1 (Spatial (None, 28, 128)           0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 196)               254800    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 2)                 394       \n","=================================================================\n","Total params: 511,194\n","Trainable params: 511,194\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2oEfI5zgN4Xx","colab_type":"code","colab":{},"outputId":"c6478987-3318-4653-93fa-c55e5c170938"},"source":["Y = pd.get_dummies(data['sentiment']).values\n","X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.15, random_state = 42)\n","print(X_train.shape,Y_train.shape)\n","print(X_test.shape,Y_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(9119, 28) (9119, 2)\n","(1610, 28) (1610, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ek38J2DeN4Xz","colab_type":"code","colab":{}},"source":["batch_size = 32\n","model.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zbm11ohON4X3","colab_type":"code","colab":{},"outputId":"3fbf8de3-3412-42af-9363-ee59b55f9032"},"source":["score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n","print(\"score: %.2f\" % (score))\n","print(\"acc: %.2f\" % (acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["score: 0.51\n","acc: 0.84\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aiRsK2oIN4X5","colab_type":"code","colab":{},"outputId":"d1c3388d-3508-425d-e69b-f2443c267832"},"source":["pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n","\n","for x in range(len(X_test)):\n","    \n","    result = model.predict(X_test[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n","   \n","    if np.argmax(result) == np.argmax(Y_test[x]):\n","        if np.argmax(Y_test[x]) == 0:\n","            neg_correct += 1\n","        else:\n","            pos_correct += 1\n","       \n","    if np.argmax(Y_test[x]) == 0:\n","        neg_cnt += 1\n","    else:\n","        pos_cnt += 1\n","\n","print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n","print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["pos_acc 48.466257668711656 %\n","neg_acc 93.14641744548287 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PT3VSfhfN4X8","colab_type":"code","colab":{},"outputId":"ad5e19b5-51c8-45c1-f043-c0edd10b862c"},"source":["twt = ['He is a true and smart leader with lots of energy.']\n","#vectorizing the tweet by the pre-fitted tokenizer instance\n","twt = tokenizer.texts_to_sequences(twt)\n","#padding the tweet to have exactly the same shape as `embedding_2` input\n","twt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\n","print(twt)\n","sentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\n","if(np.argmax(sentiment) == 0):\n","    print(\"negative\")\n","elif (np.argmax(sentiment) == 1):\n","    print(\"positive\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0    0    0   32    5    7  398    8  340   45 1081    6 1977]]\n","positive\n"],"name":"stdout"}]}]}