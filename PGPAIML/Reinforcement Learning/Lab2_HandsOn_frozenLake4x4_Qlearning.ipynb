{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Lab2_HandsOn_frozenLake4x4_Qlearning.ipynb","version":"0.3.2","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"CA0BVvUx_iaZ","colab_type":"text"},"source":["# Solving Frozen Lake 4x4 Environment"]},{"cell_type":"markdown","metadata":{"id":"HOD0bX8i_iaa","colab_type":"text"},"source":["## Find optimal policy to reach state 'G' (goal) from state 'S' (starting state)"]},{"cell_type":"code","metadata":{"id":"El9mtygB_iaa","colab_type":"code","colab":{}},"source":["import gym\n","import numpy as np\n","import time, pickle, os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfNCIplf_iad","colab_type":"code","colab":{}},"source":["env = gym.make('FrozenLake-v0')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RMHsX32C_iaf","colab_type":"code","colab":{}},"source":["epsilon = 0.9\n","total_episodes = 10000\n","max_steps = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7YR8-Dxb_iah","colab_type":"code","colab":{}},"source":["alpha = 0.81 # 0.618\n","gamma = 0.96"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNT2Nh06_iaj","colab_type":"code","colab":{}},"source":["state = env.reset()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmDLl4v4_ial","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"outputId":"cd699dcb-a6e7-42b0-9d23-b8b306d4c5fd","executionInfo":{"status":"ok","timestamp":1565498700703,"user_tz":-330,"elapsed":985,"user":{"displayName":"Vangari Gopinath","photoUrl":"https://lh4.googleusercontent.com/-KCwVHwCOp1c/AAAAAAAAAAI/AAAAAAAAAEI/BCqYLWR6NbM/s64/photo.jpg","userId":"10245542672734137653"}}},"source":["env.render()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ir6tF1fY_iao","colab_type":"text"},"source":["## Q-Learning"]},{"cell_type":"code","metadata":{"id":"Ku4VsOUS_iap","colab_type":"code","colab":{}},"source":["Q = np.zeros((env.observation_space.n, env.action_space.n))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8pj6cTE_iaq","colab_type":"code","colab":{}},"source":["total_episodes = 5000\n","G = 0\n","alpha = 0.618"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_-utXcU_ias","colab_type":"code","colab":{}},"source":["## Write your learning code\n","for episode in range(1,episodes+1):\n","    done = False\n","    G, reward = 0,0\n","    state = env.reset()\n","    while done != True:\n","        action = np.argmax(Q[state]) \n","        state2, reward, done, info = env.step(action)\n","         \n","        Q[state,action] += alpha * ((reward + (np.max(Q[state2]))  - Q[state,action]))\n","        G += reward\n","        state = state2\n","        \n","    if episode % 100 == 0:\n","        print('Episode {} Total Reward: {}'.format(episode,G))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lyixlpM_iav","colab_type":"text"},"source":["### Analyse output"]},{"cell_type":"code","metadata":{"id":"DEC7gp9-_iav","colab_type":"code","colab":{}},"source":["Q"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a679ci0z_iax","colab_type":"code","colab":{}},"source":["state = env.reset()\n","done = None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EJU2Ae0Z_iaz","colab_type":"code","colab":{}},"source":["while done != True:\n","    # We simply take the action with the highest Q Value\n","    action = np.argmax(Q[state])\n","    state, reward, done, info = env.step(action)\n","    env.render()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oWsysy1L_ia1","colab_type":"text"},"source":["## Q Learning: Exploration Vs. Exploitation"]},{"cell_type":"code","metadata":{"id":"aAy-tIJY_ia1","colab_type":"code","colab":{}},"source":["def choose_action(state):\n","    action=0\n","    if np.random.uniform(0, 1) < epsilon:\n","        action = env.action_space.sample()\n","    else:\n","        action = np.argmax(Q[state, :])\n","    return action"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUmaa8OT_ia3","colab_type":"code","colab":{}},"source":["def learn(state, state2, reward, action):\n","    predict = Q[state, action]\n","    target = reward + gamma * np.max(Q[state2, :])\n","    Q[state, action] = Q[state, action] + alpha * (target - predict)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0BxvxpZp_ia5","colab_type":"code","colab":{}},"source":["## Write your learning code"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_5TKs0DT_ia7","colab_type":"text"},"source":["### Analyse output"]},{"cell_type":"code","metadata":{"id":"SD_NNx7H_ia7","colab_type":"code","colab":{}},"source":["Q"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rj8fle4R_ia9","colab_type":"code","colab":{}},"source":["state = env.reset()\n","done = None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nI-RyfoN_ia_","colab_type":"code","colab":{}},"source":["while done != True:\n","    # We simply take the action with the highest Q Value\n","    action = np.argmax(Q[state])\n","    state, reward, done, info = env.step(action)\n","    env.render()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3EtdHmM_ibC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}